{
  "hash": "252adcc316075bf433013b1bce27db23",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"05 Performance Measures\"\nauthor: \"Maximilian Muza\"\ndate: \"6/6/2024\"\n---\n\n\n# Libraries\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cowplot)\nlibrary(glue)\n```\n:::\n\n\n# Source Automated ML h2O Code\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"04_automated_ml_h2o_2.R\")\n```\n:::\n\n\n# 1. Leaderboard Visualization\nVisualize the leaderboard to see how different models perform according to the logloss and auc performance metrics.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Transform AutoML leaderboard\nautoml_models_h2o@leaderboard %>% \n  as_tibble() %>% \n  select(-c(mean_per_class_error, rmse, mse))\n\n# Method for plotting h2O leaderboard\nplot_h2o_leaderboard <- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n  \n  # Setup inputs\n  # adjust input so that all formats are working\n  order_by <- tolower(order_by[[1]])\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n    mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n    rownames_to_column(var = \"rowname\") %>%\n    mutate(model_id = paste0(rowname, \". \", model_id) %>% as.factor())\n  \n  # Transformation\n  if (order_by == \"auc\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(auc),\n        model_type = as.factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else if (order_by == \"logloss\") {\n    \n    data_transformed_tbl <- leaderboard_tbl %>%\n      slice(1:n_max) %>%\n      mutate(\n        model_id   = as_factor(model_id) %>% reorder(logloss) %>% fct_rev(),\n        model_type = as.factor(model_type)\n      ) %>%\n      pivot_longer(cols = -c(model_id, model_type, rowname), \n                   names_to = \"key\", \n                   values_to = \"value\", \n                   names_transform = list(key = forcats::fct_inorder)\n      )\n    \n  } else {\n    # If nothing is supplied\n    stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n  }\n  \n  # Visualization\n  g <- data_transformed_tbl %>%\n    ggplot(aes(value, model_id, color = model_type)) +\n    geom_point(size = size) +\n    facet_wrap(~ key, scales = \"free_x\") +\n    labs(title = \"Leaderboard Metrics\",\n         subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n         y = \"Model Postion, Model ID\", x = \"\")\n  \n  if (include_lbl) g <- g + geom_label(aes(label = round(value, 2), \n                                           hjust = \"inward\"))\n  \n  return(g)\n  \n}\n\n# Plot leaderboard\nplot_h2o_leaderboard(automl_models_h2o@leaderboard, order_by = \"auc\")\n```\n:::\n\n![Leaderboard Visualization](../../assets/img/leaderboard_visualization.png)\n\n# 2. Model Hyperparameter Tuning with Grid Search\nML models have hyperparameter which can be further tuned to improve the ML model performance. For a stacked ensemble model this may be for example the number of trees and max_depth of the trees. Grid search is one potential way to determine the best performing set of hyperparameters. Thus, grid search is applied below for the best performing model with default hyperparameters.\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- automl_models_h2o@leader\nmodel\n\nh2o.performance(model, newdata = test_h2o)\n\nhyper_params = list(\n  ntrees = c(7,8,9,10,11,12),\n  max_depth = c(4,8,12,16, 18, 20)\n)\n\ngrid = h2o.grid(\n  algorithm = \"gbm\",\n  grid_id = \"grid\",\n  x = x,\n  y = y,\n  training_frame   = train_h2o,\n  validation_frame = valid_h2o,\n  nfolds = 5,\n  hyper_params = hyper_params\n)\ngrid\n\nbest_model <- h2o.getModel(\"grid_model_26\")\nbest_model %>% h2o.auc(train = T, valid = T, xval = T)\n\nh2o.getGrid(grid_id = \"grid\", sort_by = \"auc\", decreasing = TRUE)\n```\n:::\n\n\n# 3. Visualization of Trade-off between Precision, Recall and Optimal Threshold\nHere the trade-off between the precision and the recall metric is visualized. As well as the optimal threshold between precision and recall is highlighted in the same figure.\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance_h2o <- h2o.performance(best_model, newdata = test_h2o)\n\nperformance_tbl <- performance_h2o %>%\n  h2o.metric() %>%\n  as_tibble() \n\nperformance_tbl %>% glimpse()\n\nh2o.auc(performance_h2o, train = T, valid = T, xval = T)\n\nh2o.auc(best_model, train = T, valid = T, xval = T)\n\nh2o.giniCoef(performance_h2o)\nh2o.logloss(performance_h2o)\n\n# result for the training data\nh2o.confusionMatrix(best_model)\n\n# result for the hold out set\nh2o.confusionMatrix(performance_h2o)\n\ntheme_new <- theme(\n  legend.position  = \"bottom\",\n  legend.key       = element_blank(),,\n  panel.background = element_rect(fill   = \"transparent\"),\n  panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n  panel.grid.major = element_line(color = \"grey\", size = 0.333)\n) \n\nperformance_tbl %>%\n  filter(f1 == max(f1))\n\nperformance_tbl %>%\n  ggplot(aes(x = threshold)) +\n  geom_line(aes(y = precision), color = \"blue\", size = 1) +\n  geom_line(aes(y = recall), color = \"red\", size = 1) +\n  \n  # Insert line where precision and recall are harmonically optimized\n  geom_vline(\n    xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")\n  ) +\n  labs(title = \"Precision vs Recall\", y = \"value\") +\n  theme_new\n```\n:::\n\n![Trade-off Precision-Recall](../../assets/img/trade_off_precision_recall.png)\n\n# 4. ROC Plot\nHere the ROC plot is visualized and plotted. The ROC plot is a graphical representation used to evalute the performance of a binary classification model. It illustrates the trade-offs between the true positive rate (TPR) and the false positive rate (FPR).\n\n::: {.cell}\n\n```{.r .cell-code}\npath <- \"models/StackedEnsemble_AllModels_1_AutoML_1_20240612_120110\"\n\nload_model_performance_metrics <- function(path, test_tbl) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = test_h2o) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc)\n  \n}\n\nfs::dir_info(path = models_dir)\n\nmodel_metrics_tbl <- fs::dir_info(path = models_dir) %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%\n  unnest(cols = metrics)\n\nmodel_metrics_tbl\n\nmodel_metrics_tbl %>%\n  mutate(\n    # Extract the model names\n    path = str_split(path, pattern = \"/\", simplify = T)[,2] %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(fpr, tpr, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  \n  # just for demonstration purposes\n  geom_abline(color = \"red\", linetype = \"dotted\") +\n  \n  theme_new +\n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"ROC Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n```\n:::\n\n![ROC Plot](../../assets/img/ROC_Plot.png)\n\n# 5. Precision vs Recall Plot\nThis plot displays the precision against the recall. The recall is being displayed on the x-axis and the precision on the y-axis.\n\n::: {.cell}\n\n```{.r .cell-code}\nload_model_performance_metrics <- function(path, test_tbl) {\n  \n  model_h2o <- h2o.loadModel(path)\n  perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n  \n  perf_h2o %>%\n    h2o.metric() %>%\n    as_tibble() %>%\n    mutate(auc = h2o.auc(perf_h2o)) %>%\n    select(tpr, fpr, auc, precision, recall)\n  \n}\n\nfs::dir_info(path = models_dir)\n\nmodel_metrics_tbl <- fs::dir_info(path = models_dir) %>%\n  select(path) %>%\n  mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%\n  unnest(cols = metrics)\nmodel_metrics_tbl\n\nmodel_metrics_tbl %>%\n  mutate(\n    path = str_split(path, pattern = \"/\", simplify = T)[,2] %>% as_factor(),\n    auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n  ) %>%\n  ggplot(aes(recall, precision, color = path, linetype = auc)) +\n  geom_line(size = 1) +\n  theme_new + \n  theme(\n    legend.direction = \"vertical\",\n  ) +\n  labs(\n    title = \"Precision vs Recall Plot\",\n    subtitle = \"Performance of 3 Top Performing Models\"\n  )\n```\n:::\n\n![Precision vs. Recall](../../assets/img/precision_recall_plot_2.png)\n\n# 6. Gain Plot\n\n::: {.cell}\n\n```{.r .cell-code}\ngain_lift_tbl <- performance_h2o %>%\n  h2o.gainsLift() %>%\n  as.tibble()\n\n## Gain Chart\ngain_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"lift\")) %>%\n  mutate(baseline = cumulative_data_fraction) %>%\n  rename(gain     = cumulative_capture_rate) %>%\n  # prepare the data for the plotting (for the color and group aesthetics)\n  pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Gain Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Gain\"\n  ) +\n  theme_new\n```\n:::\n\n![Gain Plot](../../assets/img/gain_plot)\n\n# 7. Lift Plot\n\n::: {.cell}\n\n```{.r .cell-code}\nlift_transformed_tbl <- gain_lift_tbl %>% \n  select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n  select(-contains(\"capture\")) %>%\n  mutate(baseline = 1) %>%\n  rename(lift = cumulative_lift) %>%\n  pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %>%\n  ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n  geom_line(size = 1.5) +\n  labs(\n    title = \"Lift Chart\",\n    x = \"Cumulative Data Fraction\",\n    y = \"Lift\"\n  ) +\n  theme_new\n```\n:::\n\n![Lift Plot](../../assets/img/lift_chart.png)\n\n# 8. Dashboard with cowplot\n\n::: {.cell}\n\n```{.r .cell-code}\nh2o_leaderboard <- automl_models_h2o@leaderboard\nnewdata <- test_tbl\norder_by <- \"auc\"\nmax_models <- 4\nsize <- 1\n\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n  \n  # Inputs\n  \n  leaderboard_tbl <- h2o_leaderboard %>%\n    as_tibble() %>%\n    slice(1:max_models)\n  \n  newdata_tbl <- newdata %>%\n    as_tibble()\n  \n  # Selecting the first, if nothing is provided\n  order_by      <- tolower(order_by[[1]]) \n  \n  # Convert string stored in a variable to column name (symbol)\n  order_by_expr <- rlang::sym(order_by)\n  \n  # Turn of the progress bars ( opposite h2o.show_progress())\n  h2o.no_progress()\n  \n  # 1. Model metrics\n  \n  get_model_performance_metrics <- function(model_id, test_tbl) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n    \n    perf_h2o %>%\n      h2o.metric() %>%\n      as.tibble() %>%\n      select(threshold, tpr, fpr, precision, recall)\n    \n  }\n  \n  model_metrics_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        # programmatically reorder factors depending on order_by\n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    )\n  \n  \n  # 1A. ROC Plot\n  \n  p1 <- model_metrics_tbl %>%\n    ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n    theme(legend.direction = \"vertical\") \n  \n  \n  # 1B. Precision vs Recall\n  \n  p2 <- model_metrics_tbl %>%\n    ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    theme_new +\n    labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n    theme(legend.position = \"none\") \n  \n  \n  # 2. Gain / Lift\n  \n  get_gain_lift <- function(model_id, test_tbl) {\n    \n    model_h2o <- h2o.getModel(model_id)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %>%\n      h2o.gainsLift() %>%\n      as.tibble() %>%\n      select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n    \n  }\n  \n  gain_lift_tbl <- leaderboard_tbl %>%\n    mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n    unnest(cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n        fct_reorder(!! order_by_expr, \n                    .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc  = auc %>% \n        round(3) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id)),\n      logloss = logloss %>% \n        round(4) %>% \n        as.character() %>% \n        as_factor() %>% \n        fct_reorder(as.numeric(model_id))\n    ) %>%\n    rename(\n      gain = cumulative_capture_rate,\n      lift = cumulative_lift\n    ) \n  \n  # 2A. Gain Plot\n  \n  p3 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, gain, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size,) +\n    geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Gain\",\n         x = \"Cumulative Data Fraction\", y = \"Gain\") +\n    theme(legend.position = \"none\")\n  \n  # 2B. Lift Plot\n  \n  p4 <- gain_lift_tbl %>%\n    ggplot(aes(cumulative_data_fraction, lift, \n               color = model_id, linetype = !! order_by_expr)) +\n    geom_line(size = size) +\n    geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                 color = \"red\", size = size, linetype = \"dotted\") +\n    theme_new +\n    expand_limits(x = c(0, 1), y = c(0, 1)) +\n    labs(title = \"Lift\",\n         x = \"Cumulative Data Fraction\", y = \"Lift\") +\n    theme(legend.position = \"none\") \n  \n  \n  # Combine using cowplot\n  \n  # cowplot::get_legend extracts a legend from a ggplot object\n  p_legend <- get_legend(p1)\n  # Remove legend from p1\n  p1 <- p1 + theme(legend.position = \"none\")\n  \n  # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n  p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n  \n  # cowplot::ggdraw() sets up a drawing layer\n  p_title <- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n  \n  p_subtitle <- ggdraw() + \n    draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n               color = \"#2C3E50\")\n  \n  # Combine everything\n  ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n                   \n                   # Adjust the relative spacing, so that the legends always fits\n                   ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n  \n  h2o.show_progress()\n  \n  return(ret)\n  \n}\n\nautoml_models_h2o@leaderboard %>%\n  plot_h2o_performance(newdata = test_tbl, order_by = \"logloss\", \n                       size = 0.5, max_models = 4)\n```\n:::\n\n![Combined Plots](../../assets/img/combined_plots.png)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}